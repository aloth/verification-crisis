# The Verification Crisis

**Expert Perceptions of GenAI Disinformation and the Case for Reproducible Provenance**

[![Survey: Seeking Experts](https://img.shields.io/badge/Survey-Seeking_Experts-brightgreen?style=for-the-badge)](https://forms.gle/BCwYFtfqxmZewkL97)
[![Paper: R2CASS @ WWW 2026](https://img.shields.io/badge/Paper-R2CASS_@_WWW_2026-blue?style=for-the-badge)](https://thewebconf.org/)
[![arXiv](https://img.shields.io/badge/arXiv-2602.02100-B31B1B.svg?style=for-the-badge)](https://arxiv.org/abs/2602.02100)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow?style=for-the-badge)](https://opensource.org/licenses/MIT)
[![Built with olcli](https://img.shields.io/badge/Built_with-olcli-orange?style=for-the-badge&logo=latex)](https://github.com/aloth/olcli)

---

## Call for Expert Participation

> *"We are at a critical inflection point. GenAI has reduced the cost of producing disinformation to near-zero. Your expertise matters."*

We are conducting a **longitudinal research study** to understand how experts perceive the evolving threat landscape of AI-generated disinformation. This is **Wave 2** of our ongoing study—your voice will directly shape policy recommendations and reproducible mitigation frameworks.

<p align="center">
  <a href="https://forms.gle/BCwYFtfqxmZewkL97">
    <img src="https://img.shields.io/badge/TAKE_THE_SURVEY-15_minutes-success?style=for-the-badge&labelColor=2ea44f" alt="Take the Survey">
  </a>
</p>

### Who Should Participate?

We are seeking **domain experts** with professional experience in:

| Domain | Examples |
|--------|----------|
| **AI/ML Research & Engineering** | Researchers working on LLMs, diffusion models, synthetic media detection |
| **Cybersecurity** | Threat intelligence, adversarial ML, platform security |
| **Digital Policy & Regulation** | Policymakers, regulators, governance specialists (EU AI Act, DSA, etc.) |
| **Journalism & Fact-Checking** | Investigative journalists, fact-checkers, media analysts |
| **Computational Social Science** | Researchers studying online behavior, misinformation dynamics |
| **Ethics & Law** | AI ethicists, legal scholars focused on synthetic media |

### Why Participate?

- **Shape the research:** Your insights directly inform academic findings and policy recommendations
- **GDPR-compliant & anonymous:** Responses are anonymized; optional attribution in acknowledgments
- **Time commitment:** Approximately 15 minutes
- **Stay informed:** Receive a summary of findings upon publication

---

## Key Concepts

| Concept | Definition |
|---------|------------|
| **Verification Crisis** | The structural shift where GenAI reduces the cost of producing high-fidelity disinformation toward zero, risking the erosion of shared factual basis in democratic deliberation |
| **Epistemic Fragmentation** | The breakdown of a shared reality as personalized synthetic content creates isolated information bubbles |
| **Synthetic Consensus** | The artificial manufacture of apparent agreement through AI-generated content simulating public opinion |
| **Reproducible Provenance** | Transparent, standardized infrastructure for verifying information origins—treating information integrity as infrastructure |

---

## Citation

If you use this work in your research, please cite:

```bibtex
@inproceedings{loth2026verification,
  author    = {Loth, Alexander and Kappes, Martin and Pahl, Marc-Oliver},
  title     = {The Verification Crisis: Expert Perceptions of GenAI Disinformation and the Case for Reproducible Provenance},
  booktitle = {Companion Proceedings of the ACM Web Conference 2026 (WWW '26 Companion)},
  year      = {2026},
  month     = apr,
  publisher = {ACM},
  address   = {New York, NY, USA},
  location  = {Dubai, United Arab Emirates},
  DOI       = {10.1145/3774905.3795484},
  note      = {To appear. Also available as arXiv:2602.02100}
}
```

> **Note:** This paper presents findings from **Wave 1** of our longitudinal study. We are actively collecting expert responses for **Wave 2** and plan a follow-up publication with expanded insights. [Participate now](https://forms.gle/BCwYFtfqxmZewkL97) to contribute to future research.

---

## Authors

- **Alexander Loth** — Frankfurt University of Applied Sciences, Germany  
  [![ORCID](https://img.shields.io/badge/ORCID-0009--0003--9327--6865-green?logo=orcid)](https://orcid.org/0009-0003-9327-6865)
- **Martin Kappes** — Frankfurt University of Applied Sciences, Germany
- **Marc-Oliver Pahl** — IMT Atlantique, UMR IRISA, Chaire Cyber CNI, France  
  [![ORCID](https://img.shields.io/badge/ORCID-0000--0001--5241--3809-green?logo=orcid)](https://orcid.org/0000-0001-5241-3809)

## Related Work

This research builds on the [JudgeGPT](https://github.com/aloth/JudgeGPT) research platform—open-source infrastructure for studying human perception of AI-generated content.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

We thank the R2CASS workshop organizers—Momeni, Bleier, Dessì, and Khan—for establishing the reproducibility frameworks that inform this research.

---

<p align="center">
  <i>"We must treat information integrity as infrastructure. Just as we build roads and power grids, we must build the protocols for truth verification."</i>
  <br>
  — Survey Respondent (Policy Advisor)
</p>

<p align="center">
  <a href="https://forms.gle/BCwYFtfqxmZewkL97">
    <img src="https://img.shields.io/badge/Participate_in_the_Survey-Your_Voice_Matters-success?style=for-the-badge" alt="Take the Survey">
  </a>
</p>
